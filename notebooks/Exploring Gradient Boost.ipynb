{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost\n",
    "It turns out the cms translation software we are using to push a scikit-learn BDT back to a TMVA one was designed for Gradient Boost only. While we did a translation as an experiment for the Ada boost we used, we should try this guy out as well to see what happens and see if it is \"better\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bdt_training_scikit_tools import load_default_samples, default_training_variable_list, \\\n",
    "    test_train_samples, prep_samples, default_training, calc_performance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "from matplotlib.colors import LogNorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import mlglue.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_cut_Lxy = 1250\n",
    "default_cut_Lz = 3500\n",
    "eta_seperator_cut = 1.4\n",
    "def trim_sample(sample, cut_Lxy = default_cut_Lxy, cut_Lz = default_cut_Lz):\n",
    "    '''Trim lxy and lz cuts for a sample'''\n",
    "    return sample[((abs(sample.JetEta) > eta_seperator_cut) & (sample.mc_Lz*1000 > cut_Lz)) | ((abs(sample.JetEta) <= eta_seperator_cut) & (sample.mc_Lxy*1000 > cut_Lxy))]\n",
    "\n",
    "def trim_samples(all_events):\n",
    "    '''Trim default lxy and lz cuts for a tuple of (mj, bib, signal) samples'''\n",
    "    return (all_events[0], all_events[1], trim_sample(all_events[2]))\n",
    "\n",
    "def load_trimmed_sample(jobNo):\n",
    "    '''Load and trim a sample from a job, and record it in our sample archive'''\n",
    "    print ('Job {0}:'.format(jobNo))\n",
    "    all_events_all = load_default_samples(jobNo)\n",
    "    all_events = trim_samples(all_events_all)\n",
    "    print (\" \", [len(e.index) for e in all_events])\n",
    "    \n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 106:\n",
      "  BIB: 800000 events\n",
      "  Multijet: 800000 events\n",
      "  Signal: 800000 events\n",
      "  [800000, 800000, 504190]\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_events = load_trimmed_sample(106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_variables = ['EnergyDensity',\n",
    " 'BIBDeltaTimingM',\n",
    " 'JetPt',\n",
    " 'HadronicLayer1Fraction',\n",
    " 'ShowerCenter',\n",
    " 'JetLat',\n",
    " 'FirstClusterRadius',\n",
    " 'JetLong',\n",
    " 'MaxTrackPt',\n",
    " 'PredictedLxy',\n",
    " 'BIBDeltaTimingP',\n",
    " 'PredictedLz',\n",
    " 'SumPtOfAllTracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split into testing and training samples\n",
    "train, test = test_train_samples(input_events)\n",
    "\n",
    "# Prep samples for training\n",
    "all_events, all_events_class, training_weight, evaluation_weight = prep_samples(train[0], train[1], train[2], training_variable_list=training_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "So a simple training to see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_training (events, events_weight, events_class):\n",
    "    '''Given samples prepared, run the default \"best\" training we know how to run.\n",
    "    \n",
    "    Args:\n",
    "        events - A DF with an entry for every event, with all columns to be trained on\n",
    "        events_weight - weight assigned to each event (None if no weight is to be used)\n",
    "        events_class - the training class (0, 1, 2 for bib, mj, and signal)\n",
    "        min_leaf_fraction - fraction of sample that can be in each leaf. Defaults to 1%\n",
    "        \n",
    "    Returns\n",
    "        bdt - A trained boosted decision tree\n",
    "    '''\n",
    "    bdt = GradientBoostingClassifier()\n",
    "    \n",
    "    bdt.fit(events, events_class.Class, sample_weight = events_weight)\n",
    "    \n",
    "    # The BDT is sent back for use\n",
    "    return bdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bdt = gradient_training(all_events, training_weight, all_events_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIBBack': 191943104.5314537,\n",
       " 'BIBEff': 0.5587998577498269,\n",
       " 'BIBSsqrtB': 10.774591717872303,\n",
       " 'BIBTotalCount': 267135,\n",
       " 'BIBTotalWeight': 267135.0,\n",
       " 'BIBinBIB': 149275.0,\n",
       " 'BIBinHSS': 12081.0,\n",
       " 'BIBinMJ': 105779.0,\n",
       " 'HSSBack': 28370528.605109442,\n",
       " 'HSSEff': 0.9842896378335547,\n",
       " 'HSSSsqrtB': 31.017952900099445,\n",
       " 'HSSTotalCount': 167851,\n",
       " 'HSSTotalWeight': 167851.0,\n",
       " 'HSSinBIB': 1165.0,\n",
       " 'HSSinHSS': 165214.0,\n",
       " 'HSSinMJ': 1472.0,\n",
       " 'MJBack': 107251.0,\n",
       " 'MJEff': 0.7347801486425272,\n",
       " 'MJSsqrtB': 1863656.9468193203,\n",
       " 'MJTotalCount': 266785,\n",
       " 'MJTotalWeight': 830633099.3287433,\n",
       " 'MJinBIB': 191941939.5314537,\n",
       " 'MJinHSS': 28358447.605109442,\n",
       " 'MJinMJ': 610332712.192177}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_performance(bdt, test, training_variables=training_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtGeneral = mlglue.tree.BDTsklearn(bdt, list(all_events.columns), ['BIB', 'MJ', 'Signal'])\n",
    "bdtGeneral.to_tmva(\"training_106_test.xml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
