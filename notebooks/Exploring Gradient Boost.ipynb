{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost\n",
    "It turns out the cms translation software we are using to push a scikit-learn BDT back to a TMVA one was designed for Gradient Boost only. While we did a translation as an experiment for the Ada boost we used, we should try this guy out as well to see what happens and see if it is \"better\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bdt_training_scikit_tools import load_default_samples, default_training_variable_list, \\\n",
    "    test_train_samples, prep_samples, default_training, calc_performance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=14)\n",
    "from matplotlib.colors import LogNorm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import mlglue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_cut_Lxy = 1250\n",
    "default_cut_Lz = 3500\n",
    "eta_seperator_cut = 1.4\n",
    "def trim_sample(sample, cut_Lxy = default_cut_Lxy, cut_Lz = default_cut_Lz):\n",
    "    '''Trim lxy and lz cuts for a sample'''\n",
    "    return sample[((abs(sample.JetEta) > eta_seperator_cut) & (sample.mc_Lz*1000 > cut_Lz)) | ((abs(sample.JetEta) <= eta_seperator_cut) & (sample.mc_Lxy*1000 > cut_Lxy))]\n",
    "\n",
    "def trim_samples(all_events):\n",
    "    '''Trim default lxy and lz cuts for a tuple of (mj, bib, signal) samples'''\n",
    "    return (all_events[0], all_events[1], trim_sample(all_events[2]))\n",
    "\n",
    "def load_trimmed_sample(jobNo):\n",
    "    '''Load and trim a sample from a job, and record it in our sample archive'''\n",
    "    print ('Job {0}:'.format(jobNo))\n",
    "    all_events_all = load_default_samples(jobNo)\n",
    "    all_events = trim_samples(all_events_all)\n",
    "    print (\" \", [len(e.index) for e in all_events])\n",
    "    \n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 106:\n",
      "  BIB: 800000 events\n",
      "  Multijet: 800000 events\n",
      "  Signal: 800000 events\n",
      "  [800000, 800000, 504190]\n"
     ]
    }
   ],
   "source": [
    "input_events = load_trimmed_sample(106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_variables = ['EnergyDensity',\n",
    " 'BIBDeltaTimingM',\n",
    " 'JetPt',\n",
    " 'HadronicLayer1Fraction',\n",
    " 'ShowerCenter',\n",
    " 'JetLat',\n",
    " 'FirstClusterRadius',\n",
    " 'JetLong',\n",
    " 'MaxTrackPt',\n",
    " 'PredictedLxy',\n",
    " 'BIBDeltaTimingP',\n",
    " 'PredictedLz',\n",
    " 'SumPtOfAllTracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Split into testing and training samples\n",
    "train, test = test_train_samples(input_events)\n",
    "\n",
    "# Prep samples for training\n",
    "all_events, all_events_class, training_weight, evaluation_weight = prep_samples(train[0], train[1], train[2], training_variable_list=training_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "So a simple training to see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_training (events, events_weight, events_class):\n",
    "    '''Given samples prepared, run the default \"best\" training we know how to run.\n",
    "    \n",
    "    Args:\n",
    "        events - A DF with an entry for every event, with all columns to be trained on\n",
    "        events_weight - weight assigned to each event (None if no weight is to be used)\n",
    "        events_class - the training class (0, 1, 2 for bib, mj, and signal)\n",
    "        min_leaf_fraction - fraction of sample that can be in each leaf. Defaults to 1%\n",
    "        \n",
    "    Returns\n",
    "        bdt - A trained boosted decision tree\n",
    "    '''\n",
    "    bdt = GradientBoostingClassifier()\n",
    "    \n",
    "    bdt.fit(events, events_class.Class, sample_weight = events_weight)\n",
    "    \n",
    "    # The BDT is sent back for use\n",
    "    return bdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bdt = gradient_training(all_events, training_weight, all_events_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIBBack': 193599511.53449553,\n",
       " 'BIBEff': 0.5583469032511651,\n",
       " 'BIBSsqrtB': 10.719703571556185,\n",
       " 'BIBTotalCount': 267135,\n",
       " 'BIBTotalWeight': 267135.0,\n",
       " 'BIBinBIB': 149154.0,\n",
       " 'BIBinHSS': 12154.0,\n",
       " 'BIBinMJ': 105827.0,\n",
       " 'HSSBack': 27698386.8689085,\n",
       " 'HSSEff': 0.9845041137675676,\n",
       " 'HSSSsqrtB': 31.39888525568688,\n",
       " 'HSSTotalCount': 167851,\n",
       " 'HSSTotalWeight': 167851.0,\n",
       " 'HSSinBIB': 1135.0,\n",
       " 'HSSinHSS': 165250.0,\n",
       " 'HSSinMJ': 1466.0,\n",
       " 'MJBack': 107293.0,\n",
       " 'MJEff': 0.7335952424936667,\n",
       " 'MJSsqrtB': 1860287.4014066271,\n",
       " 'MJTotalCount': 266785,\n",
       " 'MJTotalWeight': 830633099.3287433,\n",
       " 'MJinBIB': 193598376.53449553,\n",
       " 'MJinHSS': 27686232.8689085,\n",
       " 'MJinMJ': 609348489.9253354}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_performance(bdt, test, training_variables=training_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'has_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a56d5dd6309d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbdtGeneral\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlglue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBDTsklearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'BIB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MJ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Signal'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbdtGeneral\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tmva\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_106_test.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlglue-0.2-py3.6.egg\\mlglue\\tree.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, feature_names, target_names)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mclass_tree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msklearn_trees\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0mnodetree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0msklearn_to_nodetree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodetree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m                 \u001b[0mtrees\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnodetree\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlglue-0.2-py3.6.egg\\mlglue\\tree.py\u001b[0m in \u001b[0;36msklearn_to_nodetree\u001b[1;34m(cls, nodetree, sklearn_tree, node_id, parent_id, depth)\u001b[0m\n\u001b[0;32m    127\u001b[0m         )\n\u001b[0;32m    128\u001b[0m         \u001b[0mnodetree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnodetree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0mnodetree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparent_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'has_key'"
     ]
    }
   ],
   "source": [
    "bdtGeneral = mlglue.tree.BDTsklearn(bdt, list(all_events.columns), ['BIB', 'MJ', 'Signal'])\n",
    "bdtGeneral.to_tmva(\"training_106_test.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlglue import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
